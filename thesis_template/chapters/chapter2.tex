\chapter{System Model}
\label{chap:systemModel}
\chaptermark{Second Chapter Heading}

Let us formally describe the necessary definitions and assumptions for an addressed heterogeneous scheduling problem. We consider scheduling over ARM \textsf{\textsc{big}}.\textsf{LITTLE} platform, which is introduced in Chapter~\ref{chap:intro}. However, to keep our analysis simpler, for now we restrict the platform to the case of two cores only:
%
\begin{itemize}
\item The \textsf{\textsc{big}} core \-- fast but energy-hungry;
\item The \textsf{LITTLE} core \-- slow but energy-efficient;
\end{itemize}
%
We assume every core to execute only one program at a time. We also consider no hardware-level parallelism and other optimisations at the moment.

\section{Mathematical notations}

We have $N$ programs, which are denoted by $P_1,\ldots,P_N$, to be executed concurrently over a shared \textsf{\textsc{big}}.\textsf{LITTLE} platform of $\mathcal{M}$ cores\footnote{In our analysis, $\mathcal{M}=2$: one \textsf{\textsc{big}} and one \textsf{LITTLE} cores}. These programs arrive asynchronously into a pending queue as depicted in Fig.~\ref{fig:heteroExampleOverview}. Then, at scheduling time instants a heterogeneous scheduler examines this queue and allocates available cores to the programs. The scheduler aims at optimizing a scheduling objective, which we define later. 

Every program $P_i=\{b_{i1},\ldots,b_{in_i}\}$, with each block representing a sequence of instructions. In our analysis, a program is executed block by block as depicted in Fig.~\ref{fig:s1} and~\ref{fig:s2}.
%
Block's $b_j$ processing requirements, if executing over an $m$-type core are modeled by:
%
\begin{itemize}
\item $T_{jm}$ \-- block execution time;
\smallskip
\item $E_{jm}$ \-- block energy consumption,
\end{itemize}
%
These metrics are typically collected by profiling tools, such as $\textsc{Perf}$. Thus, we consider these metrics to be known prior to our analysis, e.g. like an example in Table~\ref{tab:demandExample}.


For a given program $P_i$, parameters $\mathsf{T}_m$ and $\mathsf{E}_m$ denote its total runtime and energy consumption over $m$-type core, which are computed over all its blocks by:
%
\begin{minipage}{0.46\columnwidth}
\smallskip
\begin{equation}
\mathsf{T}^i_m=\sum_{j=1}^{n}{T_{jm}}
\end{equation}
\smallskip
\end{minipage}%
\begin{minipage}{.5\columnwidth}
\smallskip
\begin{equation}
\mathsf{E}^i_m=\sum_{j=1}^{n}{E_{jm}}
\end{equation}
\smallskip
\end{minipage}


Considering execution requirements of every $P_1,\ldots,P_n$ programs are known, our key objective is to minimize the so-called ``energy-delay product'' metric \cite{Ratkovic2015}, which is denoted by $\uprho$ and computed by:
%
\begin{equation}
\uprho = \mathsf{T} * \mathsf{E}
\end{equation}
%
where $\mathsf{T}$ and $\mathsf{E}$ denote the aggregated runtime and energy consumption of all simultaneously executed programs:

\begin{minipage}{0.4\columnwidth}
\smallskip
\begin{equation}
\mathsf{T}=\sum_{i=1}^N{T^i_{\left(m_1\dots m_{n_i}\right)}}
\end{equation}
\smallskip
\end{minipage}%
\begin{minipage}{.4\columnwidth}
\smallskip
\begin{equation}
\mathsf{E}=\sum_{i=1}^N{E^i_{\left(m_1\dots m_{n_i}\right)}}
\end{equation}
\smallskip
\end{minipage}

where $\left(m_1\dots m_{n_i}\right)$ denotes a sequence of $n_i$ blocks of program $P_i$ executed over cores $m_j\in \{1,\ldots, \mathcal{M}\}$. In fact, we aim at determining all those sequences, which result in a program execution with an optimal trade-off between runtime and energy consumption.
%more details on computing $\uprho$ are provided in Section~\ref{sec:energyDelayProduct}.
%\todo{add motivational example probably referring to some figure}

We also study scheduling efficiency for minimum average response time and energy consumption in isolation in Chapter~\ref{chap:efficiencyMetrics}.

Additionally, for the analysis simplicity, we assume that:
%
\begin{itemize}
\item Granularity unit for our analysis is one program block;
\item Two programs cannot reuse the same core at a time;
\item Blocks within a given program execute sequentially;
\item Hardware overheads are insignificant (see Section~\ref{sec:performanceOverheads});
\item Block execution can be preempted and migrated between cores (see Section~\ref{sec:schedulingTypes}).
%All program blocks execute sequentially that is block $B_{i,{j+1}}$ starts when $B_{i,j}$ completes.
\end{itemize}
%
We aim at gradually relaxing these assumptions in the future.


